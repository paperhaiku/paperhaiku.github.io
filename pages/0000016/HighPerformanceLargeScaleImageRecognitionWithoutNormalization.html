<html>

	<head>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
		<meta charset="utf-8">
	    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<link rel="stylesheet" href="../../haiku.css">
		<title>High-Performance Large-Scale Image Recognition Without Normalization | Paper Haiku</title>
		<link rel="shortcut icon" type="image/png" href="../../favicon.png"/>

		<script async src="https://www.googletagmanager.com/gtag/js?id=G-2VZT87J343"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-2VZT87J343');
		</script>

	</head>


	<body>

		<div class="header">
			<a href="../../index.html" class="heading">
				Paper Haiku
			</a>
			<div class="nav">
				<!-- <a class="nav-link" href="">Contribute</a> -->
				<!-- <a class="nav-link" href="">Request</a> -->
				<a class="nav-link" href="../../about.html">About</a>
			</div>
		</div>

		<div class="content-holder">

			<div class="content">

				<div class="content-title">
					High-Performance Large-Scale Image Recognition Without Normalization
				</div>

				<div class="content-body-top">
					<div class="content-body-top-title">
						Haiku
					</div>
					
						Why does batch norm work? <br>
					
						 <br>
					
						BN smoothens the loss landscape, <br>
					
						Enables more stable training, <br>
					
						Using large learning rates. <br>
					
						 <br>
					
						BN eliminates mean-shift, <br>
					
						Caused by ReLU, Gelu etc, <br>
					
						Which have non-zero mean activations.  <br>
					
						 <br>
					
						Then why do we want to get rid of it? <br>
					
						 <br>
					
						BN is computationally expensive! <br>
					
						BN induces train-test discrepancies in model behaviour. <br>
					
						BN breaks independence between train samples. <br>
					
						 <br>
					
						Alternative to Batch Norm <br>
					
						= Adaptive Gradient Clipping (AGC) <br>
					
						 + Modified ResNet (NFNet) <br>
					
						 <br>
					
						Take an existing SE-ResNet, and: <br>
					
						Apply Scaled Weight Std. to avoid mean shift, <br>
					
						Replace normal activations with scaled activations, <br>
					
						Make residual block variance preserving. <br>
					
						 <br>
					
						Enable training with AGC by: <br>
					
						Adaptively changing the gradient (weight update)  <br>
					
						for each neuron,  <br>
					
						if Norm(Gradient) / Norm (Weight) <br>
					
						it is above a certain value(λ). <br>
					
						 <br>
					
						Finally add latest training methods for improving accuracy: <br>
					
						+ Modify the group conv width (set to 128), <br>
					
						+ Modify the depth scaling for each residual block, <br>
					
						+ MixUp <br>
					
						+ RandAugment <br>
					
						+ CutMix <br>
					
						+ Sharpness Aware Minimization <br>
					
						+ PreTrain on 300M images <br>
					
						= Achieve SOTA! (without Batch Norm) <br>
					
						 <br>
					
						Note: <br>
					
						Although has more parameters than EfficientNet, <br>
					
						NFNets are 8x faster to train. <br>
					
				</div>

				<div class="content-body">

					<div class="content-body-left">
						<div class="content-body-left-title">
						Abstract
						</div>
						Batch normalization is a key component of most image classification models, but it has many undesirable properties stemming from its dependence on the batch size and interactions between examples. Although recent work has succeeded in training deep ResNets without normalization layers, these models do not match the test accuracies of the best batch-normalized networks, and are often unstable for large learning rates or strong data augmentations. In this work, we develop an adaptive gradient clipping technique which overcomes these instabilities, and design a significantly improved class of Normalizer-Free ResNets. Our smaller models match the test accuracy of an EfficientNet-B7 on ImageNet while being up to 8.7× faster to train, and our largest models attain a new state-of-the-art top-1 accuracy of 86.5%. In addition, Normalizer-Free models attain significantly better performance than their batch-normalized counterparts when finetuning on ImageNet after large-scale pre-training on a dataset of 300 million labeled images, with our best models obtaining an accuracy of 89.2%.
					</div>

					<div class="content-body-right">
						
						<p class="content-body-right-para">
							<span class="detailname">Tags</span> 
							<br>
							
								Image Classification;&nbsp;
							
								Novel Architecture;&nbsp;
							
								Regularization;&nbsp;
							
						</p>

						<p class="content-body-right-para">
							<span class="detailname">Level</span>
							<br> 
							Advanced				
						</p>

						
						<p class="content-body-right-para">
							<span class="detailname">ImageNet Top-1 Acc</span> 
							<br>
							89.20%
						</p>
						

						<p class="content-body-right-para">
							<span class="detailname">Paper Authors</span>
							<br>
							
								Andrew Brock,&nbsp;
							
								Soham De,&nbsp;
							
								Samuel L. Smith,&nbsp;
							
								Karen Simonyan,&nbsp;
									
						</p>

						<p class="content-body-right-para">
							<span class="detailname">Authors Affiliation</span>
							<br> 
							DeepMind
						</p>

						<p class="content-body-right-para">
							<span class="detailname">Publish Date</span>
							<br> 
							11 Feb 2021
						</p>

						<span>
						<a class="read-more-link" target="_blank" href="https://arxiv.org/pdf/2102.06171v1.pdf">
							Paper Link
						</a>
						&nbsp;
						<a class="read-more-link" href="https://paperswithcode.com/paper/high-performance-large-scale-image" target="_blank">
							Code
						</a>
						</span>
					</div>

				</div>

				<div class="content-footer">
					Haiku added on: 23 Feb 2021
				</div>
			</div>


			<div class="excerpt-holder">
				<div class="excerpt-title">
					Paper excerpts to justify the haiku
				</div>
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_01.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_02.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_03.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_04.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_05.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_06.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_07.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_08.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_09.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_10.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_11.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_12.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_13.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_14.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_15.png">
				
					<img class="excerpt-image" src="../.././papers/0000016/screenshots/0000016_16.png">
				
			</div>
		</div>


</html>