<html>

	<head>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
		<meta charset="utf-8">
	    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<link rel="stylesheet" href="../../haiku.css">
		<title>Big Transfer (BiT): General Visual Representation Learning | Paper Haiku</title>
		<link rel="shortcut icon" type="image/png" href="../../favicon.png"/>

		<script async src="https://www.googletagmanager.com/gtag/js?id=G-2VZT87J343"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'G-2VZT87J343');
		</script>

	</head>


	<body>

		<div class="header">
			<a href="../../index.html" class="heading">
				Paper Haiku
			</a>
			<div class="nav">
				<!-- <a class="nav-link" href="">Contribute</a> -->
				<!-- <a class="nav-link" href="">Request</a> -->
				<a class="nav-link" href="../../about.html">About</a>
			</div>
		</div>

		<div class="content-holder">

			<div class="content">

				<div class="content-title">
					Big Transfer (BiT): General Visual Representation Learning
				</div>

				<div class="content-body-top">
					<div class="content-body-top-title">
						Haiku
					</div>
					
						Pick a huge model (ResNet152x4),<br>
					
						Pretrained on huge dataset (JFT-300M),<br>
					
						But with new heuristics.<br>
					
						<br>
					
						Take the pretrained large model,<br>
					
						Finetune on a smaller dataset,<br>
					
						= SOTA!<br>
					
						<br>
					
						Big datasets?<br>
					
						Don’t use batch norm,<br>
					
						use group norm and weight std.<br>
					
						<br>
					
						Big datasets?<br>
					
						Don’t use MixUp<br>
					
						Use it for smaller datasets.<br>
					
				</div>

				<div class="content-body">

					<div class="content-body-left">
						<div class="content-body-left-title">
						Abstract
						</div>
						Transfer of pre-trained representations improves sample efficiency and simplifies hyperparameter tuning when training deep neural networks for vision. We revisit the paradigm of pre-training on large supervised datasets and fine-tuning the model on a target task. We scale up pre-training, and propose a simple recipe that we call Big Transfer (BiT). By combining a few carefully selected components, and transferring using a simple heuristic, we achieve strong performance on over 20 datasets. BiT performs well across a surprisingly wide range of data regimes — from 1 example per class to 1 M total examples. BiT achieves 87.5% top-1 accuracy on ILSVRC-2012, 99.4% on CIFAR-10, and 76.3% on the 19 task Visual Task Adaptation Benchmark (VTAB). On small datasets, BiT attains 76.8% on ILSVRC-2012 with 10 examples per class, and 97.0% on CIFAR-10 with 10 examples per class. We conduct detailed analysis of the main components that lead to high transfer performance.
					</div>

					<div class="content-body-right">
						<p class="content-body-right-para">
							<span class="detailname">Paper Authors</span>
							<br>
							
								Alexander Kolesnikov,&nbsp;
							
								Lucas Beyer,&nbsp;
							
								Xiaohua Zhai,&nbsp;
							
								Joan Puigcerver,&nbsp;
							
								Jessica Yung,&nbsp;
							
								Sylvain Gelly,&nbsp;
							
								Neil Houlsby,&nbsp;
									
						</p>

						<p class="content-body-right-para">
							<span class="detailname">Authors Affiliation</span>
							<br> 
							Google Research
						</p>

						
						<p class="content-body-right-para">
							<span class="detailname">ImageNet Top-1 Acc</span> 
							<br>
							87.54%
						</p>
						
						<p class="content-body-right-para">
							<span class="detailname">CIFAR-10 Accuracy</span> 
							<br>
							99.37%
						</p>
						
						<p class="content-body-right-para">
							<span class="detailname">CIFAR-100 Accuracy</span> 
							<br>
							93.51%
						</p>
						
						<p class="content-body-right-para">
							<span class="detailname">VTAB Accuracy</span> 
							<br>
							76.29%
						</p>
						

						<p class="content-body-right-para">
							<span class="detailname">Tags</span> 
							<br>
							
								Image Classification;&nbsp;
							
								Few Shot Learning;&nbsp;
							
						</p>

						<p class="content-body-right-para">
							<span class="detailname">Level</span>
							<br> 
							Advanced				
						</p>

						<span>
						<a class="read-more-link" target="_blank" href="https://arxiv.org/pdf/1912.11370v3.pdf">
							Paper Link
						</a>
						&nbsp;
						<a class="read-more-link" href="https://paperswithcode.com/paper/large-scale-learning-of-general-visual" target="_blank">
							Code
						</a>
						</span>
					</div>

				</div>

				<div class="content-footer">
					Paper Published on: 05 May 2020
					<br>
					Haiku added on: 06 Feb 2021
				</div>
			</div>


			<div class="excerpt-holder">
				<div class="excerpt-title">
					Paper excerpts to justify the haiku
				</div>
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_01.png">
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_02.png">
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_03.png">
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_04.png">
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_05.png">
				
					<img class="excerpt-image" src="../.././papers/0000003/screenshots/0000003_06.png">
				
			</div>
		</div>


</html>